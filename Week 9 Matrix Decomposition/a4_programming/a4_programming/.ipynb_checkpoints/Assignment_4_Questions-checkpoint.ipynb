{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMP3670 Assignment 4 - PCA & Dimensionality Reduction**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Enter Your Student ID:**\n",
    "\n",
    "**Your Name:** \n",
    "    \n",
    "\n",
    "**Submit:** You can write your answers in this file and submit a single Jupyter Notebook file (.ipynb) on Wattle. Rename this file with your student number as 'uXXXXXXX.ipynb'. Otherwise, you can write your programming questions in this file, and submit two files, 'uXXXXXXX.ipynb' for programming and 'uXXXXXXX.pdf' for theory. Please submit them separately instead of a zip file.\n",
    "    \n",
    "**Enter Discussion Partner IDs Below:**\n",
    "- <Enter ID 1>\n",
    "- <Enter ID 2>\n",
    "- <Enter ID 3>\n",
    "\n",
    "**Enter The URLs You Referred To:**\n",
    "- <URL 1>\n",
    "- <URL 2>\n",
    "- <URL 3>\n",
    "    \n",
    "\n",
    "**Programming Section**\n",
    "- 1.1 15%\n",
    "- 1.2 20%\n",
    "- 1.3 15%\n",
    "- 1.4 15%\n",
    "- 1.5 15%\n",
    "- 2. 20%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "**PROGRAMMING SECTION**\n",
    "---\n",
    "\n",
    "For all of the following, program the solution yourself. Don't just call a library function that does the whole question for you, or you'll get zero (no, that doesn't mean you can't use any library functions, but it does mean that you have to show you understand how to compute the answer yourself).\n",
    "\n",
    "**All written answers** should be between 50 and 500 words. If you can describe all the necessary information in 50 words, that's better. However, you'll only be graded on whether you describe the necessary ideas.\n",
    "\n",
    "\n",
    "-----------\n",
    "\n",
    "   **TASK 0.1:** You know the drill. Import Numpy and PyPlot.\n",
    "\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D #This is for 3d scatter plots.\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import scipy\n",
    "from matplotlib.pyplot import imread\n",
    "from PIL import Image\n",
    "np.random.seed(13579201)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's understand the settings of datasets.\n",
    "\n",
    "---\n",
    "We provide you with 3 pedestrian image folders, 'train', 'gallery', and 'val_query'. There are 199 images in 'train' which are used to compute the eigen pedestrians and build the projection matrix. 'Gallery' contains 90 images which belong to 15 different pedestrians. 'Val_query' has 3 images of 3 pedestrians. If two images' file name have same first four digits, then these two images belong to same pedestrian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 64\n",
    "height = 128\n",
    "dimension = (height, width, 3)\n",
    "images = []\n",
    "filename = []\n",
    "for file in os.listdir(\"./train\"):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        im = imread(\"./train/\" + file)\n",
    "        im = im.flatten() # flatten im into a vector\n",
    "        images.append(im) \n",
    "        filename.append(file)\n",
    "A_pp = np.stack(images).T # build a matrix where each column is a flattened image\n",
    "print(A_pp.shape)\n",
    "plt.imshow(A_pp[:, 0].reshape(dimension))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**TASK 1.1:** Let $A\\_{pp} \\in \\mathbb{R}^{D \\times N}$ be a matrix of data. Each column of $A\\_{pp}$ is a sample of data (1 example for instance). The rows of $A\\_{pp}$ are thus the features (dimensions) of each of these samples. Complete the function $preprocess(A\\_{pp}) = A, Q\\_norms, A\\_means$, for which:\n",
    "\n",
    "$$Q_{i,:} = A\\_{pp}_{i,:} - \\mu_i$$\n",
    "\n",
    "...where $\\mu_i = \\frac{1}{m}\\sum_j A\\_{pp}_{ij}$ .\n",
    "\n",
    "$$A_{i,:} = \\frac{Q_{i,:}}{||Q_{i,:}||_\\infty }$$\n",
    "\n",
    "\n",
    "$A \\in \\mathbb{R}^{D \\times N}$\n",
    "\n",
    "$Q_{i,:}$ is the $i^{th}$ row of $Q$.\n",
    "\n",
    "$A_{i,:}$ is the $i^{th}$ row of $A$.\n",
    "\n",
    "$||Q_{i,:}||_\\infty$ is the infinity norm of $Q_{i,:}$.\n",
    "\n",
    "$Q\\_norms \\in \\mathbb{R}^{D}$ is a vector recording $||Q_{i,:}||_\\infty$ for every feature dimension $i$.\n",
    "\n",
    "$A\\_means \\in \\mathbb{R}^{D}$ is a vector recording $\\mu_i$ for every feature dimension $i$.\n",
    "\n",
    "\n",
    "**HINT:** \n",
    "- If the norm is 0, divide by 1 instead.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(A_pp):\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "A, Q_norms, A_means = preprocess(A_pp)\n",
    "print(A)\n",
    "print(Q_norms)\n",
    "print(A_means.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "$A \\in \\mathbb{R}^{D \\times N}$ as above is a matrix of data where every column is a sample of data, and every row is a feature of that data. In this case, we're going to be working with images. Each column $A_{:,j}$ of $A$ is an image of a pedestrian. \n",
    "\n",
    "\"But an image is a square grid with three color channels\" you might be thinking. Well, we've simply taken every column of the image and stacked them vertically, converting a 64 column $ \\times $ 128 row pixel image with 3 channels into a vector which length is 24576.\n",
    "\n",
    "Hence $D = 24576$ and we have $N = 199$ images.\n",
    "\n",
    "Our objective is to describe each image of a pedestrian as a linear combination of other images. These other images are called Eigen Pedestrians. The Eigen Pedestrians, when flattenned into a column vector, is 24576 dimensional. These vectors are the Eigenvectors of the matrix $AA^T$.\n",
    "\n",
    "---\n",
    "\n",
    "**TASK 1.2:** Use $np.linalg.eig()$ and the functions you defined above to complete the function $eigen\\_person(A) = F, D$.\n",
    "\n",
    "$D$ is the matrix of eigen values. \n",
    "\n",
    "$F$ is the eigen pedestrians.\n",
    "\n",
    "Make sure you preprocess the data.\n",
    "\n",
    "**HINT:** \n",
    "- You'll need to ensure the columns of $F$ are unit vectors.\n",
    "- np.cov()\n",
    "- np.linalg.eig()\n",
    "- Matrix size is a big issue when calculating the eigen values. You need to make sure it won't take too much **space or time**.\n",
    "- If you've computed things correctly, all your eigen values should be real numbers (the imaginary components should be 0). Thus, you can ignore the error about imaginary / complex values.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eigen_ped(A):\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "\n",
    "#For the purposes of doing this assignment, this code isn't really here. Pretend it's engraved in rock.\n",
    "F, D = eigen_ped(A)\n",
    "F_real = np.real(F)\n",
    "print('Orthogonality Check (should be close to 0): ', F_real[:, 0].T@F_real[:, 1])\n",
    "print('Unit Vector Check: ', math.isclose(np.linalg.norm(F_real[:,0]), 1))\n",
    "print(F.shape) # It should be (24576, 199)\n",
    "print(D.shape) # It should be (24576)\n",
    "\n",
    "# The visulisation of an Eigen Pedestrain should **look like** a pedestrain.\n",
    "print('Visualise an Eigen Pedestrain:')\n",
    "ep = np.rint((F[:,0] * Q_norms + A_means).reshape(dimension)).astype(int)\n",
    "plt.imshow(ep)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Recall the lecture, in which we rotated a vector until we found the largest value for the projection of the data onto that vector.\n",
    "\n",
    "This was the eigen vector corresponding to the largest eigen value of that dataset. It was the \"direction of greatest variance\".\n",
    "\n",
    "An eigen value $d_j$ in the $j^{th}$ column of $D$ (the matrix of eigen values), is associated with an eigen vector (or eigen pedestrian) in the $j^{th}$ column $f_j$ of $F$.\n",
    "\n",
    "The variance of the data in the direction of $f_j$ is exactly $d_j$. So the $\\sum_j d_j$ is the total variance of the dataset in all directions.\n",
    "\n",
    "When we project the dataset onto an eigen pedestrian $f_k$, we \"capture\" a percentage of this variance $\\frac{d_k}{\\sum_j d_j}$. For example, if $\\sum_j d_j = 100$, and we project our data on to the 2 eigen pedestrians $f_1$ and $f_2$ with corresponding eigen values $d_1 = 19$ and $d_2 = 3$, then we've captured $\\frac{22}{100} = 22\\%$ of the variance of the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "**TASK 1.3:** Complete the function: \n",
    "\n",
    "$$reduce\\_dimensionality(image\\_vector, k, F, D, A\\_means, Q\\_norms) = compressed\\_image, p$$\n",
    "\n",
    "This function projects an image vector onto the $k$ eigen pedestrians corresponding to the $k$ largest eigen values, and returns the coefficients of the compressed image $compressed\\_image$ and the number $p$, which is percentage of variance captured by the $k$ eigen pedestrians.\n",
    "\n",
    "**HINT:** \n",
    "- Remember to preprocess the image vector.\n",
    "- In the original version of this question, you were expected to modify the input parameters. This is no longer required as I've included them below as needed. \n",
    "- $compressed\\_image \\in \\mathbb{R}^{N}$. In the below example, $k=80$, so $compressed\\_image$ should have $80$ non-zero elements, and $N-80$ elements which are 0.\n",
    "- np.eig() automatically orders eigen values for you.\n",
    "- As a general tip with arrays, remember, writing array = Img will turn array into Img. Instead, us array = Img.copy().\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dimensionality(image_vector, k, F, D, A_means, Q_norms):\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "\n",
    "# Display Code. Leave it alooooooooooone.\n",
    "Idx = 0\n",
    "compressed_image, p = reduce_dimensionality(A_pp[:, Idx], 80, F, D, A_means, Q_norms)\n",
    "print(compressed_image.shape) # should be (199,)\n",
    "print('Variance Captured:', int(p * 100), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 1.4:** Now, we have $compressed\\_image$ and eigen pedestrians $F$. We can represent an image by a linear combination of eigen pedestrians. \n",
    "\n",
    "Complete the function\n",
    "\n",
    "$$reconstruct\\_image(compressed\\_image, F, Q\\_norms, A\\_means) = R$$\n",
    "\n",
    "$compressed\\_image$ is the feature of an image after dimension reduction. \n",
    "\n",
    "$F$ is the eigen pedestrians.\n",
    "\n",
    "$R$ is the reconstructed image. $R \\in \\mathbb{R}^{128 \\times 64 \\times 3}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_image(compressed_image, F, Q_norms, A_means):\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "#Display Code. Leave it alooooooooooone.\n",
    "R_c = reconstruct_image(compressed_image, F, Q_norms, A_means)\n",
    "print('Compressed Image: ')\n",
    "plt.imshow(R_c)\n",
    "plt.show()\n",
    "Img = A[:, Idx]\n",
    "R_o = A_pp[:, Idx].reshape(dimension)\n",
    "print('Original Image')\n",
    "plt.imshow(R_o)\n",
    "plt.show()\n",
    "\n",
    "# Two images should look similar. The compressed image may be a little more blurry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets using the tool to do a simple classification task.\n",
    "\n",
    "**TASK 1.5:** Complete the function: \n",
    "\n",
    "$$the\\_nearest\\_image(query\\_image,gallery\\_images, k, F, D, A\\_means, Q\\_norms) = index\\_of\\_the\\_nearest\\_image$$\n",
    "\n",
    "Using the function in Task 1.3 to project an image vector onto the $k$ eigen pedestrians corresponding to the $k$ largest eigen values. \n",
    "Use this projection for a nearest-neighbour search over all the 90 persons. Returns the index of the nearest image.\n",
    "\n",
    "The index of the first image is zero. \n",
    "\n",
    "**HINT:** \n",
    "- $query\\_image$ and $gallery\\_images$ are not preprocessed.\n",
    "- First you need to calculate all compressed image, then make search.\n",
    "- Using Euclidean distance to calculate the distance between two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def the_nearest_image(query_image, gallery_images, k, F, D, A_means, Q_norms):\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Display Code. Leave it alooooooooooone.\n",
    "# read a query image\n",
    "query_image = imread(\"./val_query/0227_c2s1_046476_01.jpg\")\n",
    "query_image = query_image.flatten()\n",
    "\n",
    "# read gallery images\n",
    "gallery_images = []\n",
    "original_gallery_images = []\n",
    "filename = []\n",
    "for file in os.listdir(\"./gallery\"):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        im = imread(\"./gallery/\" + file)\n",
    "        original_gallery_images.append(im)\n",
    "        im = im.flatten() # flatten im into a vector\n",
    "        gallery_images.append(im) \n",
    "        filename.append(file)\n",
    "        \n",
    "original_gallery_images = np.array(original_gallery_images)\n",
    "gallery_images = np.stack(gallery_images).T\n",
    "\n",
    "idx = the_nearest_image(query_image, gallery_images, 80, F, D, A_means, Q_norms)\n",
    "plt.imshow(query_image.reshape(dimension))\n",
    "plt.show()\n",
    "plt.imshow(gallery_images[:, idx].reshape(dimension))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 2:** Complete the function\n",
    "   \n",
    "$$image\\_similarity\\_ranking(image\\_gallery, query) = list\\_of\\_index\\_of\\_the\\_images$$\n",
    "\n",
    "Image_gallery is the collection of all 90 images with dimension $90 \\times 128 \\times 64 \\times 3$.\n",
    "\n",
    "Query is one image with dimension $128 \\times 64 \\times 3$.\n",
    "\n",
    "Unlike Task 1.5, the return value should be a list filled with indices. The index should correspond to the sorted gallery images according to their similarities with the query. That is, the first element in the index corresponds to the image with the highest similarity to the query. The second element in the index corresponds to the image with second highest similarity to the query, etc. The length of the result should be 90, same as the number of gallery images. **The indices of the images in the gallery start from zero**. \n",
    "\n",
    "\n",
    "**Requirements:** \n",
    "- Use pixels of images as features.\n",
    "- Use PCA algorithm you implemented in Task 1.3 to reduce the dimensions of features.\n",
    "- You are free to tune the dimensions of the features after dimensionality reduction.\n",
    "- You are free to improve the distance metrics.\n",
    "\n",
    "Marking criteria: We have a testing set that you are not allowed to access. Our evaluation process will calculate a matching score, a weighted sum of your top-1, 2, 3, 4, 5 accuracy using some test queries (not provided to students). These test queries will be used to probe your gallery data (90 images). Top-k accuracy measures the percentage of queries for which you could find the true match within the top-k position of the rank list. Your mark will be given based on your accuracy. For example, if your implementation is better than the baseline, say a 9.5 accuracy on testing set, you will receive 20 marks; If your accuracy is lower than the baseline, you will get 10 marks. If your program contains errors/bugs, you will receive 0. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_similarity_ranking(image_gallery, image_query):\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "# Display Code. Leave it alooooooooooone.\n",
    "\n",
    "id_list = image_similarity_ranking(original_gallery_images, imread(\"./val_query/0227_c2s1_046476_01.jpg\"))\n",
    "\n",
    "plt.imshow(imread(\"./val_query/0227_c2s1_046476_01.jpg\"))\n",
    "plt.show()\n",
    "plt.imshow(original_gallery_images[id_list[0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_score(name, rr):\n",
    "    def reid(idx):\n",
    "        return filename[rr[idx]][:4]\n",
    "    base = 0.0\n",
    "    code = name[:4]\n",
    "    if reid(0) == code or reid(1) == code or reid(2) == code:\n",
    "        base += 0.4\n",
    "        if (reid(0) == code):\n",
    "            base += 0.3\n",
    "        elif (reid(1) == code):\n",
    "            base += 0.2\n",
    "        elif (reid(2) == code):\n",
    "            base += 0.1\n",
    "        if (reid(0) == code and reid(1) == code) or (reid(0) == code and reid(2) == code) or (reid(1) == code and reid(2) == code):\n",
    "            base += 0.2\n",
    "            if (reid(0) == code and reid(1) == code and reid(2) == code):\n",
    "                base += 0.1\n",
    "    else:\n",
    "        if (reid(3) == code):\n",
    "            base += 0.4\n",
    "        elif (reid(4) == code):\n",
    "            base += 0.2\n",
    "    return base\n",
    "\n",
    "def total_score():\n",
    "    score = 0\n",
    "    for file in os.listdir(\"./val_query\"):\n",
    "        rr = image_similarity_ranking(original_gallery_images, imread(\"./val_query/\" + file))\n",
    "        #_, rr = the_nearest_image(imread(\"./test/\" + file).flatten(), A_pp, 30, F, D, A_means, Q_norms)\n",
    "        score += match_score(file, rr)\n",
    "    return score\n",
    "total_score()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
